<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> 名古屋大學留學二年目 | Wen-Chin Huang 黃文勁 </title> <meta name="author" content="Wen-Chin Huang"> <meta name="description" content="在日本念計算機科學博士是怎樣的一個體驗？"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://unilight.github.io/blog/2021/NU-second-year/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Wen-Chin Huang 黃文勁 </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">名古屋大學留學二年目</h1> <p class="post-meta"> Created in July 25, 2021 </p> <p class="post-tags"> <a href="/blog/2021"> <i class="fa-solid fa-calendar fa-sm"></i> 2021 </a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p><em>註：本文同步張貼於我個人的<a href="https://medium.com/%E5%90%8D%E5%8F%A4%E5%B1%8B%E5%A4%A7%E5%AD%B8%E7%95%99%E5%AD%B8%E5%88%86%E4%BA%AB/%E5%90%8D%E5%8F%A4%E5%B1%8B%E5%A4%A7%E5%AD%B8%E7%95%99%E5%AD%B8%E4%BA%8C%E9%BB%9E%E4%BA%94%E5%B9%B4%E7%9B%AE-513078f93c3" target="blank" rel="external nofollow noopener">medium</a>。</em></p> <p>&gt; 在日本念計算機科學博士是怎樣的一個體驗？</p> <p>（這個副標題的來由是臉書常常會推薦給我的一些中國網友拍的小影片）</p> <p>距離這個系列（？）的上一篇文已經一年半了（文末有連結），當時因為新冠肺炎的疫情在日本的新學期開始時爆發，導致我無法回到日本，因此我是在台灣寫下留學第一年的心得；沒想到如今寫這篇文時我依然是在台灣，真是始料未及…我在台灣唸這個研究所的時間已經超過在日本的時間了，都不知道該不該說是「留學」了呢…</p> <p>如果你沒看過第一篇文，在此自我介紹一下。2018年6月我從台灣大學資訊系畢業，2019年4月進入了「名古屋大学 大学院情報学研究科」（Graduate school of Informatics，簡單說就是CS的研究所）的戸田研究室，先花了兩年取得了碩士學位（用敝校的講法是「博士前期課程」），於2021年4月本地直升，開始了博士生生涯（「博士後期課程」），預計於2024年3月畢業。我同時是日本學術振興會DC1特別研究員，接受來自日本政府的獎助金。 <a href="https://kaken.nii.ac.jp/ja/grant/KAKENHI-PROJECT-21J20920/" target="blank" rel="external nofollow noopener">https://kaken.nii.ac.jp/ja/grant/KAKENHI-PROJECT-21J20920/</a></p> <p>之所以選在兩年半的這個時間寫這篇文，是因為第二年結束時覺得「留學二年目」實在是沒什麼好寫的，畢竟都不在日本…時至今日，博士生涯開始了半年，覺得還是有些東西可以分享，便決定來寫這篇文。礙於篇幅，本文決定聚焦於以下三點進行分享。跟念博士有關的事情…請讓我富堅至下篇吧。</p> <ul> <li>中間發表</li> <li>修論發表</li> <li>申請博班獎學金</li> </ul> <h2 id="碩士二年目">碩士二年目</h2> <p>如上一篇文所寫，敝系對於碩士生的畢業要求是修超過30學分+碩論審查通過。一般碩士生都會在第一年把課全部修完，如果沒有要往上唸的話，第二年前半努力找工作，找到之後再開始努力寫碩論。而我因為一入學就決定要攻讀博士，因此第二年要做的事情很單純…繼續努力做研究就對了。話雖如此，還是有些跟研究相關的小事件。</p> <h3 id="中間發表">中間發表</h3> <p>中間發表在台大敝系似乎比較少看到（也許存在於其他學校或者系所？），但在日本蠻常見的。以敝系為例，通常於碩二的一開始（四月初）舉辦，有點類似一個小型的校內學術會議：早上每位發表者輪流上去做兩分鐘的研究介紹 ，下午則是poster session。這個中間發表雖然是強制性的，但比起「打分數」，我覺得更像是「確定你有在做事」以及「讓你知道你多慘」：藉由這樣一個公開的場合，來讓那些很混的碩士生發現自己的研究進度明顯落後其他人。不得不說，這的確很像日本人會做的事。</p> <p>（為什麼早上的研究介紹只有兩分鐘，我想原因有兩個：(1) 多數日本碩士生並非以研究者為職涯目標，因此研究內容通常兩分鐘就可以簡短講完，不需要更久的時間。(2) 日本人對於研究的想法是「先有應用才有方法」，每個人的研究都可以被包裝成一個很完整的故事（這跟台灣大多數剛開始做研究的學生是相反的），所以對於如何言簡意賅的介紹自己的研究而言，是個適合的長度。） 中間發表是以「専攻」為單位進行的，因此是個可以一窺其他研究室都在做些什麼題目的好機會。「専攻」的英文翻譯為department，乍聽會以為是「系」，但我覺得概念類似於台灣研究所中的「組」，例如台大電信所裡面有電波組、通信組等等。我所屬的是「知能システム専攻」（Intelligent system），簡單說就是AI組，因此可以聽到其他研究室都在做些什麼題目。常見的題目包括醫療影像辨識、自駕車等等，較冷門的題目如地形偵測、法令檢索與翻譯、自動食譜生成…都是一些很有趣的題目呢。</p> <p>中間發表除了校內，也有地區版本的。敝實驗室是做語音訊號處理的，因此參加了「東海地区音声関連研究室修士論文中間発表会」，舉辦在學期末的八月初。流程與內容和校內中間發表基本上一樣，只不過主題限定在語音相關，且會有來自東海地區（愛知、岐阜、三重、靜岡）的學校參加。如果說校內中間發表有強制性，那這個地區版本的存在意義我就不是很懂了。教授們之間要交流的話，多的是其他的日本國內會議，而碩士生間的交流意義就更低了，畢竟都沒有要認真走研究這條路呀。</p> <p>受到新冠肺炎的影響，校內的中間發表被延期到了八月底，且兩個中間發表都改成線上，這也是疫情爆發後我第一次參加線上學術會議。正好東海中間發表今年輪到名大舉辦，因此這兩次中間發表基本上是同一群人辦的。敝系教授們所採取的形式是將所有人切成4個session，然後分配給每個人一個zoom房間連結，想聽的人就會點連結進來聽講。這個形式乍聽沒有問題，但問題出在一個session只有45分鐘，而進出zoom房間實在是太浪費時間了，可能要對這個題目非常有興趣才會想要進去聽講。如果我是日本人，看到我是個留學生，可能就不太會有興趣進來。雖然不排除我的題目大家沒興趣，但在我的45分鐘session中，進來聽講的不到五位，覺得實在是有點淒涼啊。</p> <h3 id="修論發表">修論發表</h3> <p>在台灣的碩士論文審查（或稱碩士論文口試）參加人數很少，大多只有報告者以及數位擔任口試委員的教授，而一些就讀台大其他研究所的同學們告訴我，實驗室會盡量將應屆碩士畢業生的論文口試集中在一到兩天，輪流上去報告給同樣一批的口委聽，這樣可以動員整個實驗室的人力去借教室、設定器材，也可以讓實驗室後輩旁聽、預先了解口試狀況，水果點心便當也比較好訂（？）。但就算如此，整個口試還是以實驗室為單位而已。</p> <p>在名大的狀況則是完全不一樣。在這裡我們的碩士論文口試被稱為「修論発表審査会」，一樣是以專攻為單位舉辦。整個修論發表分為兩天進行，教務處會事先排好所有應屆碩士生的發表順序，從早上九點開始到中午一點，再從兩點一路到六點，兩天總計要讓近四十人全部發表完畢。我在碩一快結束時參加了大我一屆學長姐的修論發表，場地辦在我們系館最大間的教室，前面坐滿了本系的教授以及一些從外部找來的口委，中間架著攝影機，後半則都是穿著西裝（男女都要）看起來緊張到快吐的應屆碩士生們，整個氣氛可說是相當肅殺。一個人有十五分鐘的發表時間加上五分鐘的問答時間，在場數十位有各自研究背景的教授都可以問問題，問題可說是五花八門。因為同一個實驗室的會被排在相近的時間，我跟其他三個同期碩一生只聽了我們實驗室學長姐的發表。他們都很自動的分工起來，有人拿相機拍照，有人幫忙記錄口委的問題，這讓修論發表變成了整個實驗室的大事。</p> <p>今年初，因為日本跟台灣的疫情都趨緩，我原本以為會被強迫飛回去參加口試，結果學校拖到一月中才宣布改為線上。跟中間發表的poster session性質不同，修論發表就只是單純一個一個上去報告而已，就沒有什麼zoom切來切去的問題。但相對的，少了面對面的臨場感，在只看得到部分開著鏡頭的教授的狀況下，修論發表的那種隆重感與儀式感就不見了；而且大概因為是線上口試，教授問問題的次數也變少，結束後有種「這樣就結束了嗎？」的惆悵感。</p> <p>修論發表有個比較特別的地方是還兼「本地直升博士的碩士生」的博士入學口試。除了自己的碩士論文內容外，還要報告博士研究預計要做的內容及規劃，因此發表時間從十五分鐘變成…二十分鐘。從只增加五分鐘這點，可以知道教授們其實沒有預期你在目標計劃這點著墨太多，畢竟那只是看你會不會嘴砲而已，主要還是從碩士論文報告中窺見這個學生是不是那塊料。我們這些本地直升的被排在第二天的最後，人數出乎我意料的多，有將近十人，我還真不知道有這麼多人想念博士。實際聽了一輪其他人的發表後，我真的有點搞糊塗了…在我的想象中，應該要對研究不排斥，起碼做出一些興趣與心得，才考慮要不要繼續往上攻讀。但如果兩年研究下來，什麼發表都沒有，這樣真的適合念博士嗎…好為他們擔心啊。</p> <h3 id="申請博班獎學金jsps-dc1-fellowship">申請博班獎學金：JSPS DC1 Fellowship</h3> <p>在我碩二時花上我非常多時間的一件事，就是申請日本學術振興會（簡稱學振）的博士生特別研究員DC1。要念研究所，金錢絕對是個重要的元素。在歐美，博士生與教授接近僱傭關係，教授通常會支付博士生主要的薪水，厲害一點的博士生則在入學時就會拿到一些有條件的獎學金（當一年TA或RA等）。在台灣，大部分的碩士生都可以領實驗室的補助，一個月數千元不等。雖然多數是要當教授的TA，但我也有聽過什麼都不做，躺著就有錢領的。 而在日本，教授給研究生的錢是非常少的。首先，碩士生一般是不給錢，這點我真的嚇到，剛進研究室時，我猶豫非常久要不要問教授這件事，直到我發現同期的碩士生都有在打工，打聽之下才發現教授不會給錢。至於博士生，教授一般會聘你當RA，但礙於日本人對外國人的打工時間限制（稱為「資格外活動許可」）為一週二十八小時，算一算給的錢頂多付個房租水電飯錢就沒了，所以大部分博士生都得自己去申請獎學金。日本有非常多種類的獎學金，多數都是要還的 — 沒錯，要還！等同於沒有利息的學貸。剩下不用還的獎學金中，大多數由民間機構提供，且年份較短，多數都只提供一年份，一個月的錢也不多。因此，要找到符合不用還、一次提供三年、獎金豐富這三個條件的，大概就剩下學振特別研究員DC1了。</p> <p>學振特別研究員DC1（以下簡稱DC1）是日本博士生可以拿到最高等級的fellowship（不同於scholarship，可以想成是給做研究的人的獎學金，金額比較高），期間為三年，除了每個月可領20萬日圓（接近日本一般大學畢業生月收），每年更有接近100萬日圓的研究經費可以申請，可以拿去買器材、國內出差或者出國參加國際會議等等。除此之外，DC1的審查非常嚴格，要寫長達10頁的研究計畫，除了要介紹目前為止的研究，還得詳述博士研究的計畫、方法、原創性、對社會的貢獻等，最後再寫自己的優勢與長處。根據統計，每一年數千件的申請中，僅錄取七百個名額，約20%的採用率。如此豐厚的獎金加上極低的採用率，讓DC1本身享有很高的榮譽，對履歷有大大的加分：例如，大部分在日本能當上教授的人，幾乎都有這個DC1的經歷。甚至如果在網路上搜尋，可以找到許多教人家怎麼寫申請書的文章，甚至出書的也有！</p> <p>我在四五月時花了非常多時間心力在撰寫申請資料，因為我自己覺得以我的狀況，應該會是場硬仗。首先，審查雖然會分科系，請專門的教授審查，但是因為博士研究主題都很細，所以基本上要把審查員教授當作是外行人。如何把計畫內容寫得深入淺出，讓教授一眼就能看出潛力與可行性，是非常困難的。再者，我要競爭的對象是日本學生，他們一定是用日文寫；而我對我自己的日文實力實在沒有信心，因此百般思量後最後決定寫英文。這麼一來，就得要寫得更淺顯易懂，才能讓非母語的日本教授們快速了解。最後，我查了統計資料，以我要申請的情報學來看，每年被採用的留學生大約不到5人，機會渺茫…。</p> <p>回想起來，那段時間真的是非常痛苦。要寫得淺顯易懂，又要能夠強調出自己的研究突出之處，真的很難。那陣子，研究沒什麼在做，常常盯著word一下午，什麼都寫不出來。好不容易寫完之後，還得硬著頭皮寄信給一些認識的教授跟前輩，請他們以日本人的眼光看我的英文。非常幸運的，我們實驗室的一個最年輕的助理教授，他十年前也是DC1，非常熱心的來回跟我修改了快十遍，給了我很多相當有建設性的回饋。最後從他口中聽到「嗯，申請書變得相當好了呢」時，當下真是感動到不行！</p> <p>DC1的申請於每年六月中旬截止，第一波選考只有書面審查，九月下旬公布第一波結果，分為內定、採用候補、不合格三種。若被分類為採用候補，則於十月至十二月舉行第二波面試選考，最後於隔年一月放榜第二波結果。非常幸運的，我於第一波放榜時就拿到了內定，確保了接下來三年經濟來源無虞，也給了身為研究者的我一個極大的肯定。</p> <h2 id="結語">結語</h2> <p>在這疫情時代中不幸中的大幸是自己攻讀的是計算機科學領域，所有的實驗都可以透過遠端連回實驗室的伺服器完成，讓我可以在台灣繼續完成我的學業。我依然享受著一些在國外唸書的好處，例如實驗室的資源，以及教授給我的許多挑戰與機會（例如辦一場國際性學術challenge）等等，但也每天在問自己，如果當初沒有選擇回台灣放假，而是一直待在日本，不知道人生會變成怎樣？剛開始去日本時，總有著一股衝勁與熱血，有很多事情想要嘗試與完成；現在就算可以回去日本了，不知道自己還能不能保有那顆闖蕩的心…總之，按照現況來看，明年有很大的機會可以打完兩劑疫苗回日本，希望下一篇留學分享文能是在日本寫下囉！</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/displaying-external-posts-on-your-al-folio-blog/">Displaying External Posts on Your al-folio Blog</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2020/NU-first-year/">名古屋大學留學一年目</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Wen-Chin Huang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: August 20, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"publications by categories in reversed chronological order. generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-repositories",title:"repositories",description:"Edit the `_data/repositories.yml` and change the `github_users` and `github_repos` lists to include your own GitHub profile and repositories.",section:"Navigation",handler:()=>{window.location.href="/repositories/"}},{id:"nav-teaching",title:"teaching",description:"Materials for courses you taught. Replace this text with your description.",section:"Navigation",handler:()=>{window.location.href="/teaching/"}},{id:"post-google-gemini-updates-flash-1-5-gemma-2-and-project-astra",title:'Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"We\u2019re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.",section:"Posts",handler:()=>{window.open("https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/","_blank")}},{id:"post-displaying-external-posts-on-your-al-folio-blog",title:'Displaying External Posts on Your al-folio Blog <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2","_blank")}},{id:"post-\u540d\u53e4\u5c4b\u5927\u5b78\u7559\u5b78\u4e8c\u5e74\u76ee",title:"\u540d\u53e4\u5c4b\u5927\u5b78\u7559\u5b78\u4e8c\u5e74\u76ee",description:"\u5728\u65e5\u672c\u5ff5\u8a08\u7b97\u6a5f\u79d1\u5b78\u535a\u58eb\u662f\u600e\u6a23\u7684\u4e00\u500b\u9ad4\u9a57\uff1f",section:"Posts",handler:()=>{window.location.href="/blog/2021/NU-second-year/"}},{id:"post-\u540d\u53e4\u5c4b\u5927\u5b78\u7559\u5b78\u4e00\u5e74\u76ee",title:"\u540d\u53e4\u5c4b\u5927\u5b78\u7559\u5b78\u4e00\u5e74\u76ee",description:"\u8b39\u8a18\u9304\u6211\u5728\u540d\u53e4\u5c4b\u5927\u5b78\u60c5\u5831\u5b78\u7814\u7a76\u79d1\u78a9\u58eb\u8ab2\u7a0b\u7b2c\u4e00\u5e74\u6240\u9818\u609f\u5230\u7684\u4e9b\u8a31\u5fc3\u5f97\u3002",section:"Posts",handler:()=>{window.location.href="/blog/2020/NU-first-year/"}},{id:"news-one-journal-paper-cdvae-cls-gan-https-arxiv-org-pdf-2001-07849-pdf-was-accepted-to-the-ieee-transactions-on-emerging-topics-in-computational-intelligence",title:"One journal paper [[CDVAE-CLS-GAN](https://arxiv.org/pdf/2001.07849.pdf)] was accepted to the **IEEE Transactions on Emerging Topics...",description:"",section:"News"},{id:"news-i-am-co-organizing-the-voice-conversion-challenge-2020-http-www-vc-challenge-org-i-developed-a-seq-to-seq-baseline-w-espnet-https-github-com-espnet-espnet-tree-master-egs-vcc20",title:"I am co-organizing the [Voice Conversion Challenge 2020](http://www.vc-challenge.org/). I developed a [seq-to-seq baseline...",description:"",section:"News"},{id:"news-one-journal-paper-asvspoof-2019-database-https-www-sciencedirect-com-science-article-abs-pii-s0885230820300474-was-accepted-to-the-computer-speech-amp-language",title:"One journal paper [[ASVspoof 2019 database](https://www.sciencedirect.com/science/article/abs/pii/S0885230820300474)] was accepted to the **Computer Speech &amp;...",description:"",section:"News"},{id:"news-one-paper-vtn-https-unilight-github-io-publication-demos-publications-transformer-vc-was-accepted-to-interspeech-2020",title:"One paper [[VTN](https://unilight.github.io/Publication-Demos/publications/transformer-vc)] was accepted to **Interspeech 2020**.",description:"",section:"News"},{id:"news-the-implementation-of-vtn-https-github-com-espnet-espnet-tree-master-egs-arctic-vc1-is-open-sourced-on-espnet",title:"The implementation of [VTN](https://github.com/espnet/espnet/tree/master/egs/arctic/vc1) is open-sourced on **ESPnet**.",description:"",section:"News"},{id:"news-the-proceeding-https-www-isca-speech-org-archive-vcc-bc-2020-of-the-joint-workshop-for-the-blizzard-challenge-and-voice-conversion-challenge-2020-https-www-synsig-org-index-php-joint-workshop-for-the-blizzard-challenge-and-voice-conversion-challenge-2020-is-online-now",title:"The [proceeding](https://www.isca-speech.org/archive/VCC_BC_2020/) of the [Joint Workshop for the Blizzard Challenge and Voice Conversion...",description:"",section:"News"},{id:"news-four-papers-are-accepted-to-the-joint-workshop-for-the-blizzard-challenge-and-voice-conversion-challenge-2020-https-www-synsig-org-index-php-joint-workshop-for-the-blizzard-challenge-and-voice-conversion-challenge-2020-challenge-summary-https-www-isca-speech-org-archive-vcc-bc-2020-pdfs-vcc2020-paper-13-pdf-objective-assesement-https-www-isca-speech-org-archive-vcc-bc-2020-pdfs-vcc2020-paper-34-pdf-baseline-asr-tts-https-www-isca-speech-org-archive-vcc-bc-2020-pdfs-vcc2020-paper-11-pdf-nu-entry-https-www-isca-speech-org-archive-vcc-bc-2020-pdfs-vcc2020-paper-36-pdf",title:"Four papers are accepted to the [Joint Workshop for the Blizzard Challenge and...",description:"",section:"News"},{id:"news-one-journal-was-accepted-to-the-ieee-acm-transactions-on-audio-speech-and-language-processing-the-early-access-version-https-ieeexplore-ieee-org-document-9314100-is-available-now-on-ieee-xplore-there-is-also-an-arxiv-version-https-arxiv-org-abs-2008-03088",title:"One journal was accepted to the **IEEE/ACM Transactions on Audio, Speech, and Language...",description:"",section:"News"},{id:"news-two-first-author-papers-vqvae-vc-https-arxiv-org-abs-2010-12231-bert-asr-https-arxiv-org-abs-2102-00291-were-accepted-to-icassp-2021-also-two-papers-i-co-authored-crank-https-github-com-k2kobayashi-crank-nonar-seq2seq-vc-https-kan-bayashi-github-io-nonarseq2seqvc-were-also-accepted",title:"Two first-author papers [[VQVAE-VC](https://arxiv.org/abs/2010.12231)] [[BERT-ASR](https://arxiv.org/abs/2102.00291)] were accepted to **ICASSP 2021**. Also, two papers...",description:"",section:"News"},{id:"news-one-paper-ema2s-https-arxiv-org-abs-2102-03786-was-accepted-to-ieee-international-symposium-on-circuits-and-systems-iscas-2021",title:"One paper [[EMA2S](https://arxiv.org/abs/2102.03786)] was accepted to **IEEE International Symposium on Circuits and Systems...",description:"",section:"News"},{id:"news-i-successfully-defensed-my-master-39-s-thesis-assets-pdf-master-thesis-pdf-target-quot-blank-quot-also-i-successfully-passed-the-ph-d-entrance-exam-and-will-become-a-ph-d-candidate-at-the-graduate-school-of-informatics-nagoya-university",title:"I successfully defensed my [master&#39;s thesis](../assets/pdf/master-thesis.pdf){:target=&quot;_blank&quot;}. Also, I successfully passed the Ph.D. entrance...",description:"",section:"News"},{id:"news-one-first-author-paper-dysarthric-vc-w-vtn-vae-https-arxiv-org-abs-2106-01415-was-accepted-to-interspeech-2021-also-one-paper-i-co-authored-relational-data-selection-https-arxiv-org-abs-2106-05629-was-accepted",title:"One first-author paper [[Dysarthric VC w/ VTN+VAE](https://arxiv.org/abs/2106.01415)] was accepted to **Interspeech 2021**. Also,...",description:"",section:"News"},{id:"news-you-can-read-some-posts-i-wrote-in-the-blog-page-as-long-as-you-understand-mandarin-chinese",title:"You can read some posts I wrote in the blog page, as long...",description:"",section:"News"},{id:"news-i-started-my-internship-at-facebook-reality-labs-research",title:"I started my internship at **Facebook Reality Labs Research**.",description:"",section:"News"},{id:"news-three-co-author-papers-were-accepted-to-apsipa-asc-2021-elvc-w-lip-https-arxiv-org-abs-2109-03551-noisy-to-noisy-vc-investigation-of-non-parallel-seq2seq-vc-w-synthetic-data",title:"Three co-author papers were accepted to **APSIPA ASC 2021**. [[ELVC w/ lip](https://arxiv.org/abs/2109.03551)] [Noisy-to-noisy...",description:"",section:"News"},{id:"news-one-first-author-paper-prosody-for-asr-tts-vc-https-arxiv-org-abs-2107-09477-was-accepted-to-asru-2021-also-one-paper-i-co-authored-elvc-w-seq2seq-was-accepted",title:"One first-author paper [[Prosody for ASR+TTS VC](https://arxiv.org/abs/2107.09477)] was accepted to **ASRU 2021**. Also,...",description:"",section:"News"},{id:"news-received-the-best-paper-award-at-apsipa-asc-2021",title:"Received the Best Paper Award at **APSIPA ASC 2021**!",description:"",section:"News"},{id:"news-the-first-voicemos-challenge-https-nii-yamagishilab-github-io-ecooper-demo-voicemos2022-index-html-kicks-off-today-this-is-a-new-challenge-that-aims-to-compare-techniques-for-predicting-the-mean-opinion-score-mos-of-synthetic-speech-we-are-still-accepting-new-challengers-if-you-are-interested-in-participating-please-contact-us-at-voicemos2022-nii-ac-jp-voicemos2022-nii-ac-jp",title:"The first [VoiceMOS Challenge](https://nii-yamagishilab.github.io/ecooper-demo/VoiceMOS2022/index.html) kicks off today! This is a new challenge that...",description:"",section:"News"},{id:"news-the-voicemos-challenge-https-voicemos-challenge-2022-github-io-was-accepted-as-a-special-session-at-interspeech-2022-https-interspeech2022-org-program-special-php-again-we-are-still-accepting-new-challengers-if-you-are-interested-in-participating-please-contact-us-at-voicemos2022-nii-ac-jp-voicemos2022-nii-ac-jp-first-then-register-at-the-codalab-page-https-codalab-lisn-upsaclay-fr-competitions-695",title:"The [VoiceMOS Challenge](https://voicemos-challenge-2022.github.io/) was accepted as a [special session at INTERSPEECH 2022](https://interspeech2022.org/program/special.php)! Again,...",description:"",section:"News"},{id:"news-two-first-author-papers-s3prl-vc-https-arxiv-org-abs-2110-06280-ldnet-https-arxiv-org-abs-2110-09103-and-one-co-first-author-paper-n2d-vc-https-arxiv-org-abs-2110-08213-were-accepted-to-icassp-2022-also-two-papers-i-co-authored-mos-finetune-ssl-https-arxiv-org-abs-2110-02635-direct-n2n-vc-https-arxiv-org-abs-2111-07116-were-also-accepted",title:"Two first-author papers [[S3PRL-VC](https://arxiv.org/abs/2110.06280)] [[LDNet](https://arxiv.org/abs/2110.09103)] and one co-first author paper [[N2D VC](https://arxiv.org/abs/2110.08213)] were...",description:"",section:"News"},{id:"news-the-voicemos-challenge-2022-https-voicemos-challenge-2022-github-io-is-over-we-have-a-summary-paper-https-arxiv-org-abs-2203-11389-submitted-to-arxiv-the-codalab-competition-page-https-codalab-lisn-upsaclay-fr-competitions-695-is-still-opened-and-anyone-can-register-to-get-the-dataset-and-give-it-a-try",title:"The [VoiceMOS Challenge 2022](https://voicemos-challenge-2022.github.io/) is over! We have a [[summary paper](https://arxiv.org/abs/2203.11389)] submitted to...",description:"",section:"News"},{id:"news-i-was-invited-to-give-a-talk-at-\u97f3\u58f0\u8a00\u8a9e\u60c5\u5831\u51e6\u7406\u7814\u7a76\u4f1a-\u97f3\u58f0\u7814\u7a76\u4f1a-slp-sp-a-japanese-domestic-conference-slides-are-here-https-www-slideshare-net-nu-i-todalab-the-voicemos-challenge-2022",title:"I was invited to give a talk at \u97f3\u58f0\u8a00\u8a9e\u60c5\u5831\u51e6\u7406\u7814\u7a76\u4f1a/\u97f3\u58f0\u7814\u7a76\u4f1a (SLP/SP), a Japanese domestic...",description:"",section:"News"},{id:"news-i-started-my-internship-at-fair-fundamental-ai-research-meta",title:"I started my internship at **FAIR (Fundamental AI Research), Meta**.",description:"",section:"News"},{id:"news-two-papers-end-to-end-binaural-synthesis-https-arxiv-org-abs-2207-03697-voicemos-challenge-2022-https-arxiv-org-abs-2203-11389-were-accepted-to-interspeech-2022-also-one-paper-i-co-authored-ssl-for-pathological-asr-https-arxiv-org-abs-2203-15431-was-also-accepted",title:"Two papers [[End-to-end binaural synthesis](https://arxiv.org/abs/2207.03697)] [[VoiceMOS Challenge 2022](https://arxiv.org/abs/2203.11389)] were accepted to **Interspeech 2022**....",description:"",section:"News"},{id:"news-one-paper-expressive-speech-to-speech-translation-https-arxiv-org-abs-2301-10606-was-accepted-to-icassp-2023-also-one-paper-i-co-authored-intermediate-fine-tuning-for-pathological-asr-https-arxiv-org-abs-2211-01079-was-also-accepted",title:"One paper [[Expressive Speech-to-Speech Translation](https://arxiv.org/abs/2301.10606)] was accepted to **ICASSP 2023**. Also, one paper...",description:"",section:"News"},{id:"news-one-journal-was-accepted-to-the-ieee-journal-of-selected-topics-in-signal-processing-arxiv-version-https-arxiv-org-abs-2207-04356",title:"One journal was accepted to the **IEEE Journal of Selected Topics in Signal...",description:"",section:"News"},{id:"news-the-vtn-journal-paper-received-the-16th-ieee-signal-processing-society-japan-student-best-paper-award-open-access-https-ieeexplore-ieee-org-document-9314100",title:"The VTN journal paper received the **16th IEEE Signal Processing Society Japan Student...",description:"",section:"News"},{id:"news-the-first-singing-voice-conversion-challenge-http-www-vc-challenge-org-kicks-off-today-this-is-a-new-version-of-the-voice-conversion-challenge-vcc-series-that-aims-to-compare-techniques-for-singing-voice-conversion-in-contrast-to-normal-voice-conversion-we-are-still-accepting-new-challengers-if-you-are-interested-in-participating-please-fill-in-the-registration-form-https-forms-gle-2xc9vb39vjhx72ha6",title:"The first [Singing Voice Conversion Challenge](http://www.vc-challenge.org/) kicks off today! This is a new...",description:"",section:"News"},{id:"news-i-open-sourced-the-s3prl-vc-https-github-com-unilight-s3prl-vc-toolkit-it-also-comes-with-a-huggingface-spaces-demo-https-huggingface-co-spaces-unilight-s3prl-vc-vcc2020-please-check-them-out",title:"I open-sourced the [**s3prl-vc**](https://github.com/unilight/s3prl-vc) toolkit! It also comes with a [HuggingFace Spaces demo](https://huggingface.co/spaces/unilight/s3prl-vc-vcc2020)....",description:"",section:"News"},{id:"news-i-open-sourced-the-seq2seq-vc-https-github-com-unilight-seq2seq-vc-toolkit-it-is-a-toolkit-for-sequence-to-sequence-voice-conversion-research-please-check-it-out",title:"I open-sourced the [**seq2seq-vc**](https://github.com/unilight/seq2seq-vc) toolkit! It is a toolkit for sequence-to-sequence voice conversion...",description:"",section:"News"},{id:"news-i-start-serving-as-a-student-researcher-at-google-japan",title:"I start serving as a student researcher at **Google Japan**.",description:"",section:"News"},{id:"news-i-was-honored-the-outstanding-graduate-student-award-\u5b66\u8853\u5968\u52b1\u8cde-of-nagoya-university",title:"I was honored the Outstanding Graduate Student Award (\u5b66\u8853\u5968\u52b1\u8cde) of Nagoya University!",description:"",section:"News"},{id:"news-the-singing-voice-conversion-challenge-2023-http-vc-challenge-org-is-over-we-have-a-summary-paper-https-arxiv-org-abs-2306-14422-submitted-to-arxiv-there-will-also-be-a-special-session-at-asru-2023-http-www-asru2023-org-motion-asp-siteid-1007526-amp-menuid-49656-amp-postid-697225-amp-lgid-1",title:"The [Singing Voice Conversion Challenge 2023](http://vc-challenge.org/) is over! We have a [summary paper](https://arxiv.org/abs/2306.14422)...",description:"",section:"News"},{id:"news-a-paper-was-accepted-to-apsipa-asc-2023-evaluate-fac-https-arxiv-org-abs-2309-02133",title:"A paper was accepted to **APSIPA ASC 2023**. [[Evaluate-FAC](https://arxiv.org/abs/2309.02133)]",description:"",section:"News"},{id:"news-four-papers-were-presented-at-asru-2023-svcc2023-https-arxiv-org-abs-2306-14422-voicemos-challenge-2023-https-arxiv-org-abs-2310-02640-nu-svcc2023-https-arxiv-org-abs-2310-05203-n2d-vc-gst-https-arxiv-org-abs-2310-02570",title:"Four papers were presented at **ASRU 2023**. [[SVCC2023](https://arxiv.org/abs/2306.14422)] [[VoiceMOS Challenge 2023](https://arxiv.org/abs/2310.02640)] [[NU-SVCC2023](https://arxiv.org/abs/2310.05203)] [[N2D-VC-GST](https://arxiv.org/abs/2310.02570)]...",description:"",section:"News"},{id:"news-i-successfully-defended-my-ph-d-thesis-assets-pdf-phd-thesis-pdf",title:"I successfully defended my [Ph.D. thesis](./assets/pdf/phd-thesis.pdf)!",description:"",section:"News"},{id:"news-i-am-now-an-assistant-professor-at-the-graduate-school-of-informatics-nagoya-university",title:"I am now an assistant professor at the Graduate School of Informatics, Nagoya...",description:"",section:"News"},{id:"news-one-paper-was-presented-at-icassp-2024-electrolaryngeal-speech-intelligibility-enhancement-through-robust-linguistic-encoders-https-arxiv-org-abs-2309-09627",title:"One paper was presented at **ICASSP 2024**. [[Electrolaryngeal Speech Intelligibility Enhancement through Robust...",description:"",section:"News"},{id:"news-one-paper-was-accepted-to-ieee-acm-taslp-a-large-scale-evaluation-of-speech-foundation-models-https-arxiv-org-abs-2404-09385",title:"One paper was accepted to **IEEE/ACM TASLP**. [[A Large-Scale Evaluation of Speech Foundation...",description:"",section:"News"},{id:"news-one-paper-was-accepted-to-ieee-acm-taslp-pretraining-and-adaptation-techniques-for-electrolaryngeal-speech-recognition-https-ieeexplore-ieee-org-abstract-document-10533680",title:"One paper was accepted to **IEEE/ACM TASLP**. [[Pretraining and Adaptation Techniques for Electrolaryngeal...",description:"",section:"News"},{id:"news-the-voicemos-challenge-2024-https-sites-google-com-view-voicemos-challenge-past-challenges-voicemos-challenge-2024-is-officially-over-now-you-can-freely-get-the-datasets-by-registering-through-the-codabench-page-https-www-codabench-org-competitions-2650-there-will-also-be-a-special-session-at-slt-2024-https-2024-ieeeslt-org-challenges",title:"The [VoiceMOS Challenge 2024](https://sites.google.com/view/voicemos-challenge/past-challenges/voicemos-challenge-2024) is officially over! Now you can freely get the...",description:"",section:"News"},{id:"news-we-wrote-a-review-paper-on-evaluation-of-synthesis-speech-which-was-published-at-acoustical-science-and-technology-a-journal-in-japan-the-english-version-can-be-found-here-https-www-jstage-jst-go-jp-article-ast-45-4-45-e24-12-article-char-ja",title:"We wrote a review paper on evaluation of synthesis speech, which was published...",description:"",section:"News"},{id:"news-i-gave-a-lecture-on-voice-conversion-please-find-the-slides-assets-pdf-20240716-class-pdf-here",title:"I gave a lecture on voice conversion. Please find the [slides](./assets/pdf/20240716-class.pdf) here.",description:"",section:"News"},{id:"news-i-gave-an-invited-talk-https-www-citi-sinica-edu-tw-assets-htmls-iz240024-zh-html-on-voice-conversion-at-citi-academia-sinica-taiwan-please-find-the-slides-assets-others-20240814-citi-talk-pptx-here",title:"I gave an [invited talk](https://www.citi.sinica.edu.tw/assets/htmls/IZ240024_zh.html) on voice conversion at CITI, Academia Sinica, Taiwan....",description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%77%65%6E.%63%68%69%6E%68%75%61%6E%67@%67.%73%70.%6D.%69%73.%6E%61%67%6F%79%61-%75.%61%63.%6A%70","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=g71mJO4AAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/unilight","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/unilightwf","_blank")}},{id:"socials-medium",title:"Medium",section:"Socials",handler:()=>{window.open("https://medium.com/@unilight","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>